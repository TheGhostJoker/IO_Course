{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial neural network (from scratch)\n",
    "\n",
    "This is a simple implementation of a feed forward neural network. It has no hidden layers. It can perform binary classification. \n",
    "\n",
    "Here, we use to function as a two input AND gate.\n",
    "\n",
    "So we can train it on the dataset ```[[0, 0], [0, 1], [1, 0], [1, 1]]```. However, there isn't much in terms of test data, but this is just to demonstrate how neural networks generally work under the hood as working with frameworks like Tensorflow or PyTorch abstracts away all of this.\n",
    "\n",
    "This can be modified to perform binary classication on any data with two features. The number of inputs can also easily be increased by modifying a part of the code.\n",
    "\n",
    "Overview of how this works:\n",
    "\n",
    "a) Feed forward mechanism\n",
    "\n",
    "b) calculate loss\n",
    "\n",
    "c) back propogate loss (i.e., find the derivative wrt the learnable parameters)\n",
    "\n",
    "d) update the learnable parameters\n",
    "\n",
    "\n",
    "The weight matrices, input layers, hidden layers, etc., are all represented as matrices in actual implementations of neural networks. Again, this is just a proof of concept implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## number of neurons and weights\n",
    "\n",
    "As there are two inputs, we have two input nodes. And we only have one output, so we have one output node.\n",
    "There are no hidden layers. So, we have 3 nodes in total. \n",
    "\n",
    "We have two weights for the connection between input and output layer. We also have bias for the output layer.\n",
    "So the number of learnable parameters is 3.\n",
    "\n",
    "\n",
    "## sigmoid as an activation function\n",
    "\n",
    "For the output neuron, the value produced can be any number. But for this case, we want it to be a number between 0 and 1, and have a threshold of 0.5 so that anything that is less that 0.5 is given class 1 (0) and anything above 0.5 goes to class 2 (1)\n",
    "\n",
    "So we apply the sigmoid function as the activation function to the output neuron.\n",
    "\n",
    "We also need to get the derivative of sigmoid, which we do in the ```sigmoidPrime``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(w1,w2,b1,l=data_set):\n",
    "    x=0\n",
    "    for i in range(len(l)):\n",
    "        x=x+(sigmoid(w1*l[i][0]+w2*l[i][1]+b1)-l[i][2])**2\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weight1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-689a195e851f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mweight_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mweight_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mbias_u\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weight1' is not defined"
     ]
    }
   ],
   "source": [
    "#red=1 and blue=0; [(length,breadth, color)]\n",
    "data_set=[(3,1.5,1),(2,1,0),(4,1.5,1),(3,1,0),(3.5,0.5,1),(2,0.5,0),(5.5,1,1),(1,1,0)]\n",
    "#mystery flower: 4.5 x 1\n",
    "#shoud predict the color, given the dimensions.\n",
    "#using a neural network of two input nodes with weights w1,w2 and a bias b the output node gives\n",
    "# a value which, depending on whether it is closer to zero(blue) or one(red) predicts the color.\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#actication function here is the sigmoid function\n",
    "def sigmoid(x):\n",
    "    return (1/(1+numpy.e**(-x)))\n",
    "\n",
    "#cost function to measure the error\n",
    "def cost(w1,w2,b1,l=data_set):\n",
    "    x=0\n",
    "    for i in range(len(l)):\n",
    "        x=x+(sigmoid(w1*l[i][0]+w2*l[i][1]+b1)-l[i][2])**2\n",
    "    return x\n",
    "\n",
    "#predicting\n",
    "def pred(w1,w2,b,i,l=data_set):\n",
    "    return sigmoid(w1*l[i][0]+w2*l[i][1]+b)\n",
    "\n",
    "#gives the true output\n",
    "def target(i,l=data_set):\n",
    "    return l[i][2]\n",
    "\n",
    "#backpropogation \n",
    "def slope_w1(w1,w2,b,l=data_set):\n",
    "    x_s=0\n",
    "    for i in range(len(l)):\n",
    "        x_s=x_s+2*(sigmoid(w1*l[i][0]+w2*l[i][1]+b)-l[i][2])*sigmoid(w1*l[i][0]+w2*l[i][1]+b)*(1-sigmoid(w1*l[i][0]+w2*l[i][1]+b))*l[i][0]\n",
    "    return round(x_s,4)\n",
    "def slope_w2(w1,w2,b,l=data_set):\n",
    "    x_s1=0\n",
    "    for i in range(len(l)):\n",
    "        x_s1=x_s1+2*(sigmoid(w1*l[i][0]+w2*l[i][1]+b)-l[i][2])*sigmoid(w1*l[i][0]+w2*l[i][1]+b)*(1-sigmoid(w1*l[i][0]+w2*l[i][1]+b))*l[i][1]\n",
    "    return round(x_s1,4)        \n",
    "def slope_b(w1,w2,b,l=data_set):\n",
    "    x_s2=0\n",
    "    for i in range(len(l)):\n",
    "        x_s2=x_s2+2*(sigmoid(w1*l[i][0]+w2*l[i][1]+b)-l[i][2])*sigmoid(w1*l[i][0]+w2*l[i][1]+b)*(1-sigmoid(w1*l[i][0]+w2*l[i][1]+b))\n",
    "    return round(x_s2,4)  \n",
    "\n",
    "import random\n",
    "weight1 = random.randint(1,10)\n",
    "weight2 = random.randint(1,10)\n",
    "bias = random.randint(1,10)\n",
    "\n",
    "num_steps = 10\n",
    "#gradient descent to update the weights and the biases\n",
    "for i in range(num_steps):\n",
    "        a=0.1\n",
    "        print(\"slopes: \", slope_w2(weight1,weight2,bias,data_set), slope_w1(weight1,weight2,bias,data_set))\n",
    "        weight1=weight1-a*slope_w1(weight1,weight2,bias,data_set)\n",
    "        weight2=weight2-a*slope_w2(weight1,weight2,bias,data_set)\n",
    "        bias=bias-a*slope_b(weight1,weight2,bias,data_set)\n",
    "        print('it:',weight1, weight2,bias,sep=',')    \n",
    "\n",
    "def predict(x,y):\n",
    "    return sigmoid(weight1*x+weight2*y+bias)\n",
    "\n",
    "print(\"finally \")\n",
    "print('weight1: ' ,weight1,'weight2: ',weight2,'bias: ',bias)\n",
    "print(\"the length and breadth of the mystery flower: \")\n",
    "mys_l=float(input())\n",
    "mys_b=float(input())\n",
    "if round(predict(mys_l,mys_b))==1:\n",
    "    print(\"red \")\n",
    "else:\n",
    "    print(\"blue\")plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
